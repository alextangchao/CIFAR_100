# -*- coding: utf-8 -*-
"""CIFAR_100.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A6CBmw5Z9rn5zJsReLIvCwUF3zz4Yg-b
"""

import time
import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn


def showpicture():
    # @title show the picture
    import matplotlib.pyplot as plt
    import numpy as np

    # functions to show an image

    def imshow(img):
        img = img / 2 + 0.5  # unnormalize
        npimg = img.numpy()
        plt.imshow(np.transpose(npimg, (1, 2, 0)))

    # get some random training images
    dataiter = iter(trainloader)
    images, labels = dataiter.next()

    # show images
    imshow(torchvision.utils.make_grid(images))
    # print labels
    # print(' '.join('%5s' % classes[labels[j]] for j in range(4)))


def print_time(time):
    hour = time // 3600
    time %= 3600
    minute = time // 60
    time %= 60
    print("Training time: ", end="")
    if hour > 0:
        print(str(int(hour)) + " hours ", end="")
    print(str(int(minute)) + " minutes " + str(int(time)) + " seconds")


# Training the model
def train():
    print("Start training...")
    loss_function = nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
    start = time.time()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            # get the inputs
            inputs, labels = data
            # inputs = Variable(inputs).cuda()
            # labels = Variable(labels).cuda()
            inputs = inputs.to(device)
            labels = labels.to(device)
            # zero the parameter gradients
            optimizer.zero_grad()
            # forward + backward + optimize
            outputs = net(inputs)
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()

            # print statistics
            running_loss += loss.item()
            if i % 1000 == 999:  # print every 1000 mini-batches
                print('[%d, %5d] loss: %.3f' %
                      (epoch + 1, i + 1, running_loss / 1000))
                running_loss = 0.0

    end = time.time()
    print("Finished Training")
    print_time(end - start)


def check_correctness(loader):
    correct = 0
    total = 0
    with torch.no_grad():
        for data in loader:
            images, labels = data
            # images = Variable(images).cuda()
            # labels = Variable(labels).cuda()
            images = images.to(device)
            labels = labels.to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    word = ""
    if loader == trainloader:
        word = "train"
    elif loader == testloader:
        word = "test"
    correctness = 100 * correct / total
    print('Accuracy of the network on the ' + word + ' images: %d %%' % (correctness))
    return correctness


def save_model():
    torch.save(net, "D:\study\CIFAR_100\model\\" + str(test_correctness) + "_" + str(train_correctness) + "_"
               + str(int(time.time())) + ".pkl")


def load_model(dir):
    net = torch.load(dir)
    print("Finish loading the data")
    # check_correctness(trainloader)
    check_correctness(testloader)
    exit()


# Define model class
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # 3 input image channel, 6 output channels
        # 3x3 square convolution kernel
        self.conv1 = nn.Conv2d(3, 23, 5)
        self.conv2 = nn.Conv2d(23, 35, 5)
        self.conv3 = nn.Conv2d(35, 56, 5)
        self.pool = nn.MaxPool2d(2, 2)
        # an affine operation: y = Wx + b
        self.fc1 = nn.Linear(56 * 4 * 4, 800)
        self.fc2 = nn.Linear(800, 600)
        self.fc3 = nn.Linear(600, 400)
        self.fc4 = nn.Linear(400, 200)
        self.fc5 = nn.Linear(200, 100)
        self.relu = nn.ELU()

    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.pool(self.relu(self.conv2(x)))
        x = self.pool(self.relu(self.conv3(x)))
        x = x.view(-1, 56 * 4 * 4)
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.relu(self.fc3(x))
        x = self.relu(self.fc4(x))
        x = self.fc5(x)
        return x


if __name__ == "__main__":
    num_epochs = 80  # number of times which the entire dataset is passed throughout the model
    batch_size = 50  # the size of input data took for one iteration

    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
    trainset = torchvision.datasets.CIFAR100(root='./data', train=True,
                                             download=True, transform=transform)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=4)
    testset = torchvision.datasets.CIFAR100(root='./data', train=False,
                                            download=True, transform=transform)
    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                             shuffle=False, num_workers=4)

    device = torch.device("cuda: 0" if torch.cuda.is_available() else "cpu")
    print(device)

    net = Net()
    net = net.to(device)

    # load_model("D:\study\CIFAR_100\model\\25.67_76.534_1572670736.pkl")

    train()

    train_correctness = check_correctness(trainloader)
    test_correctness = check_correctness(testloader)
    save_model()
